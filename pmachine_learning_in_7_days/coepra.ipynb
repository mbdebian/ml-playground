{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoEPrA Example\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Data Shape: (89, 5788)\n"
     ]
    }
   ],
   "source": [
    "source_dataset_path = os.path.join(\"book_code\", \"Section 4\", \"CoEPrA.csv\")\n",
    "with open(source_dataset_path) as raw_data:\n",
    "    data = np.loadtxt(raw_data, delimiter=\",\")\n",
    "print(\"---> Data Shape: {}\".format(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate independent and dependent variables\n",
    "X = data[:,0:5787]\n",
    "y = data[:,5787]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Data Split for training and testing\n",
      "\tX_training shape\t'(71, 5787)'\n",
      "\tX_test shape\t\t'(18, 5787)'\n",
      "\ty_training shape\t'(71,)'\n",
      "\ty_test shape\t\t'(18,)'\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test\n",
    "print(\"---> Data Split for training and testing\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"\\tX_training shape\\t'{}'\".format(X_train.shape))\n",
    "print(\"\\tX_test shape\\t\\t'{}'\".format(X_test.shape))\n",
    "print(\"\\ty_training shape\\t'{}'\".format(y_train.shape))\n",
    "print(\"\\ty_test shape\\t\\t'{}'\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mbernal/clasificador/private_data/src/code_repos/machine_learning/ml-playground/python/lib/python3.7/site-packages/sklearn/linear_model/base.py:509: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying the linear regression approach without regularization\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Mean squared error on the training data: 0.08\n"
     ]
    }
   ],
   "source": [
    "# Make predictions using the training set and calculate the mean squared error\n",
    "y_train_pred = regr.predict(X_train)\n",
    "print(\"---> Mean squared error on the training data: {:0.2f}\".format(mean_squared_error(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Running a k-fold cross validation\n",
      "\tScores sample '[-1.58031398e+24 -6.28451759e+23 -5.89220228e+23 -1.03515026e+23\n",
      " -6.16618077e+23]'\n",
      "\tMean score: '-7.036238136104907e+23'\n"
     ]
    }
   ],
   "source": [
    "# This probably means 'overfitting', right?\n",
    "# Let's run a K-Fold Cross Validation\n",
    "scores = cross_val_score(regr, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "print(\"---> Running a k-fold cross validation\")\n",
    "print(\"\\tScores sample '{}'\".format(scores[:10]))\n",
    "print(\"\\tMean score: '{}'\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Mean squared error on the test data: 3583363366497778925568000.00\n"
     ]
    }
   ],
   "source": [
    "# Now let's try to make predictions using the testing set\n",
    "y_testing_pred = regr.predict(X_test)\n",
    "print(\"---> Mean squared error on the test data: {:0.2f}\".format(mean_squared_error(y_test, y_testing_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.3, copy_X=True, fit_intercept=True, max_iter=1000000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The mean squared error on the testing data is very high\n",
    "# Let's try again but using L1 / Lasso Regularization\n",
    "regr_lasso = linear_model.Lasso(alpha=0.3, max_iter=1000000)\n",
    "regr_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Lasso L1 model\n",
      "\tSample weights: '[-0.  0. -0.  0.  0.  0. -0.  0. -0.  0.  0. -0.  0. -0. -0.  0. -0. -0.\n",
      "  0. -0.]'\n"
     ]
    }
   ],
   "source": [
    "print(\"---> Lasso L1 model\")\n",
    "print(\"\\tSample weights: '{}'\".format(regr_lasso.coef_[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIndex of all non-zero coefficients:\n",
      "'(array([  64,  136,  445,  451,  653,  715,  760,  787,  858, 1236, 1358,\n",
      "       1422, 1430, 1732, 1737, 1874, 1879, 2065, 2247, 2374, 2380, 2581,\n",
      "       2644, 2689, 2708, 2890, 3224, 3351, 3666, 3931, 3994, 4002, 4221,\n",
      "       4303, 4510, 4573, 4574, 4637, 4645, 4819, 4952, 5153, 5154, 5280,\n",
      "       5589, 5595, 5648, 5732]),)'\n"
     ]
    }
   ],
   "source": [
    "lasso_nonzero_coef_indexes = np.nonzero(regr_lasso.coef_)\n",
    "print(\"\\tIndex of all non-zero coefficients:\\n'{}'\".format(lasso_nonzero_coef_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
